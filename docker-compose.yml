version: '3.6'
services:
  namenode:
    image: apache/hadoop:3
    hostname: namenode
    container_name: namenode
    command: [ "hdfs", "namenode", ]
    depends_on:
      - resourcemanager
      - nodemanager
    ports:
      - "9870:9870"
    env_file:
      - ./config-hadoop
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    networks:
      - my_persistent_network
    volumes:
      - hadoop:/home/
    restart: on-failure

  datanode1:
    image: apache/hadoop:3
    container_name: datanode1
    command: [ "hdfs", "datanode" ]
    depends_on:
      - namenode
    env_file:
      - ./config-hadoop
    networks:
      - my_persistent_network
    volumes:
      - hadoop:/home/
    restart: on-failure

  datanode2:
    image: apache/hadoop:3
    container_name: datanode2
    command: [ "hdfs", "datanode" ]
    depends_on:
      - namenode
    env_file:
      - ./config-hadoop
    networks:
      - my_persistent_network
    volumes:
      - hadoop:/home/
    restart: on-failure

  resourcemanager:
    image: apache/hadoop:3
    hostname: resourcemanager
    container_name: resourcemanager
    command: [ "yarn", "resourcemanager" ]
    ports:
      - "8088:8088"
    env_file:
      - ./config-hadoop
    volumes:
      - ./test.sh:/opt/test.sh
    networks:
      - my_persistent_network
    restart: on-failure

  nodemanager:
    image: apache/hadoop:3
    hostname: nodemanager
    container_name: nodemanager
    command: [ "yarn", "nodemanager" ]
    env_file:
      - ./config-hadoop
    networks:
      - my_persistent_network
    volumes:
      - hadoop:/home/
    restart: on-failure

  broker01:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    container_name: broker01
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,CLIENT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://broker01:9092,CONTROLLER://broker01:9093,CLIENT://broker01:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker01:9092,CLIENT://broker01:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker01:9093,2@broker02:9093'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_JMX_PORT: 9090
      KAFKA_LOG_DIRS: /var/log/kafka
      KAFKA_NUM_PARTITIONS: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_ENABLE: 'false'
    volumes:
      - ./config/kafka_init/run_workaround.sh:/tmp/run_workaround.sh
    ports:
      - '9092:9094'
    mem_limit: ${MEM_LIMIT}
    command: "bash -c '/tmp/run_workaround.sh && /etc/confluent/docker/run'"
    healthcheck:
      test: nc -z broker01 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network

  broker02:
    image: confluentinc/cp-kafka:${CONFLUENT_VERSION}
    container_name: broker02
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,CLIENT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://broker02:9092,CONTROLLER://broker02:9093,CLIENT://broker02:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker02:9092,CLIENT://broker02:9094
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker01:9093,2@broker02:9093'
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_JMX_PORT: 9090
      KAFKA_LOG_DIRS: /var/log/kafka
      KAFKA_NUM_PARTITIONS: 2
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_ENABLE: 'false'
    volumes:
      - ./config/kafka_init/run_workaround.sh:/tmp/run_workaround.sh
    ports:
      - '9094:9094'
    mem_limit: ${MEM_LIMIT}
    command: "bash -c '/tmp/run_workaround.sh && /etc/confluent/docker/run'"
    healthcheck:
      test: nc -z broker02 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network

#  kc01:
#    image: confluentinc/cp-kafka-connect:${CONFLUENT_VERSION}
#    container_name: kc01
#    ports:
#      - '8083:8083'
#    depends_on:
#      broker01:
#        condition: service_healthy
#      broker02:
#        condition: service_healthy
#    volumes:
#      - ./connectors:/home/appuser/connectors
#      - ./libs:/home/appuser/libs
#    environment:
#      CLASSPATH: /home/appuser/libs/*
#      CONNECT_BOOTSTRAP_SERVERS: "broker01:9092,broker02:9092"
#      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect01"
#      CONNECT_REST_PORT: 8083
#      CONNECT_GROUP_ID: kafka-connect-vdt
#      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
#      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
#      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
#      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
#      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
#      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/,/home/appuser/connectors/'
#    mem_limit: ${MEM_LIMIT}
#    command:
#      - bash
#      - -c
#      - |
#        # Run kafka
#        echo "Launching Kafka Connect worker"
#        /etc/confluent/docker/run &
#        #
#        sleep infinity
#    healthcheck:
#      test: nc -z kc01 8083 || exit -1
#      start_period: 15s
#      interval: 5s
#      timeout: 10s
#      retries: 10
#    networks:
#      - my_persistent_network
#
#  kc02:
#    image: confluentinc/cp-kafka-connect:${CONFLUENT_VERSION}
#    container_name: kc02
#    ports:
#      - '8093:8083'
#    depends_on:
#      broker01:
#        condition: service_healthy
#      broker02:
#        condition: service_healthy
#    volumes:
#      - ./connectors:/home/appuser/connectors
#      - ./libs:/home/appuser/libs
#    environment:
#      CLASSPATH: /home/appuser/libs/*
#      CONNECT_BOOTSTRAP_SERVERS: "broker01:9092,broker02:9092"
#      CONNECT_REST_ADVERTISED_HOST_NAME: "kc02"
#      CONNECT_REST_PORT: 8083
#      CONNECT_GROUP_ID: kafka-connect-vdt
#      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
#      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
#      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
#      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
#      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
#      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
#      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
#      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
#      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/,/home/appuser/connectors/'
#    mem_limit: ${MEM_LIMIT}
#    command:
#      - bash
#      - -c
#      - |
#        # Run kafka
#        echo "Launching Kafka Connect worker"
#        /etc/confluent/docker/run &
#        #
#        sleep infinity
#    healthcheck:
#      test: nc -z kc02 8083 || exit -1
#      start_period: 15s
#      interval: 5s
#      timeout: 10s
#      retries: 10
#    networks:
#      - my_persistent_network
#
#  kafka-ui:
#    container_name: kafka-ui
#    image: provectuslabs/kafka-ui:latest
#    ports:
#      - '8080:8080'
#    depends_on:
#      broker01:
#        condition: service_healthy
#      broker02:
#        condition: service_healthy
#      kc01:
#        condition: service_healthy
#      kc02:
#        condition: service_healthy
#    environment:
#      KAFKA_CLUSTERS_0_NAME: vdt-kafka-cluster
#      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker01:9092,broker02:9092
#      KAFKA_CLUSTERS_0_METRICS_PORT: 9090
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: kc01
#      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kc01:8083
#      KAFKA_CLUSTERS_0_KAFKACONNECT_1_NAME: kc02
#      KAFKA_CLUSTERS_0_KAFKACONNECT_1_ADDRESS: http://kc02:8083
#    mem_limit: ${MEM_LIMIT}
#    healthcheck:
#      test: nc -z kafka-ui 8080 || exit -1
#      start_period: 15s
#      interval: 5s
#      timeout: 10s
#      retries: 10
#    networks:
#      - my_persistent_network
  zookeeper:
    hostname: myzookeeper
    image: confluentinc/cp-zookeeper:${CONFLUENT_VERSION}
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "2181:2181"
    container_name: zookeeper
    healthcheck:
      test: nc -z zookeeper 2181 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      - my_persistent_network
  registry:
    hostname: myregistry
    container_name: registry_container_persistent
    image: 'apache/nifi-registry:1.15.0' 
    restart: on-failure
    ports:
      - "18080:18080"
    environment:
      - LOG_LEVEL=INFO
      - NIFI_REGISTRY_DB_DIR=/opt/nifi-registry/nifi-registry-current/database
      - NIFI_REGISTRY_FLOW_PROVIDER=file
      - NIFI_REGISTRY_FLOW_STORAGE_DIR=/opt/nifi-registry/nifi-registry-current/flow_storage
    volumes:
      - ./nifi_registry/database:/opt/nifi-registry/nifi-registry-current/database
      - ./nifi_registry/flow_storage:/opt/nifi-registry/nifi-registry-current/flow_storage
    networks:
      - my_persistent_network
    # data extraction, transformation and load service
  nifi:
    hostname: mynifi
    container_name: nifi_container_persistent
    image: 'apache/nifi:1.14.0'
    restart: on-failure
    ports:
      - '8091:8080'
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_CLUSTER_IS_NODE=true
      - NIFI_CLUSTER_NODE_PROTOCOL_PORT=8082
      - NIFI_ZK_CONNECT_STRING=myzookeeper:2181
      - NIFI_ELECTION_MAX_WAIT=30 sec
      - NIFI_SENSITIVE_PROPS_KEY='12345678901234567890A'
    healthcheck:
      test: "${DOCKER_HEALTHCHECK_TEST:-curl localhost:8091/nifi/}"
      interval: "60s"
      timeout: "3s"
      start_period: "5s"
      retries: 5
    volumes:
      - ./nifi/database_repository:/opt/nifi/nifi-current/database_repository
      - ./nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      - ./nifi/content_repository:/opt/nifi/nifi-current/content_repository
      - ./nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
      - ./nifi/state:/opt/nifi/nifi-current/state
      - ./nifi/logs:/opt/nifi/nifi-current/logs
      - ./nifi/conf:/opt/nifi/nifi-current/conf
    networks:
      - my_persistent_network
volumes:
  hadoop:

networks:
  my_persistent_network:
    driver: bridge